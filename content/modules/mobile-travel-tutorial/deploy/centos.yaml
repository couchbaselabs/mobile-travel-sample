requirements: |

  - Vagrant 1.8.1
  - Virtualbox

chapters:
  - title: Deploy
    lessons:
      - title: Spin Up & Install
        milestones:
          - title: Installing preliminaries
            description: |
              If you're running through this workshop on the day at Couchbase Connect Silicon Valley, you'll be able to take advantage of pre-loading some files needed to speed up the process and avoid having to wait for downloads. In either case, you'll need to install both [Vagrant](https://www.vagrantup.com/) and a compatible version (5.1) of [Virtualbox](https://www.virtualbox.org/wiki/Download_Old_Builds_5_1) 

              ## Installing Virtualbox and Vagrant

              Installers are available for compatible version of Virtualbox and Vagrant for both macOS and Windows. You can install these as you would any other piece of software.

              ## Cloning the Repo

              The files you need for this workshop are all contained in the GitHub repo [couchbaselabs/connect_mobile_deploy](https://github.com/couchbaselabs/connect_mobile_deploy). These files are all quite small so we don't need to worry about the download time. Simply clone this repo to your local machine:

              ```bash
              git clone https://github.com/couchbaselabs/connect_mobile_deploy.git
              ```

              or

              ```bash
              $ git clone git@github.com:couchbaselabs/connect_mobile_deploy.git
              ```

              **If you're not running this on the day of Couchbase Connect, or don't want to take advantage of the pre-supplied files and instead let them get downloaded automatically, skip the rest of this section and move on to Spin Up & Install: Couchbase Server**

              ## Adding the Vagrant Base Box

              The file `connect_sv.box` is a copy of the Vagrant Base Box used by default for this workshop, `puppetlabs/centos-7.0-64-puppet`. In order to save having to download this we can tell Vagrant to use `connect_sv` instead of the *real* `puppetlabs/centos-7.0-64-puppet`.

              - First, we need to add the box to Vagrant:

              ```bash
              $ vagrant box add /path/to/pre-supplied/connect_sv.box --name connect_sv
              ```

              - Then we need to set the environment variable `VAGRANT_OS` to ensure we use this in the rest of the workshop:

              ```bash
              $ export VAGRANT_OS="pre-supplied"
              ```

              ## Adding the Couchbase Server and Sync Gateway Packages

              Once the packages for Couchbase Server and Sync Gateway have been downloaded once, they'll be reused by subsequent vagrants. If they're already present, they never need to be downloaded in the first place. All that needs to be done here is to copy the files into the same directory as the `Vagrantfile`.

          - title: Couchbase Server
            description: |

              To deploy Couchbase Mobile to production you must first get familiar with Couchbase Server. While it's certainly possible to run Sync Gateway in isolation for quick and agile development and testing, any production deployment needs Couchbase Server as the back-end. Luckily, connecting the two is incredibly easy. Even more luckily, both Couchbase Server and Sync Gateway are designed to be able to scale out easily and with zero downtime, meaning that we can start with a very small deployment and scale it up later to something that's production ready.
              Couchbase Server can deployed on a whole host of [operating systems](http://www.couchbase.com/nosql-databases/downloads), but for this workshop we'll focus on using CentOS 7.

              ## Spin Up Instances with Vagrant

              - You should already have [Vagrant](https://www.vagrantup.com/) installed, so simply navigate to the directory of the repo you cloned earlier and run the command `vagrant up`. You should get a fairly verbose output that starts by detailing the two machines we're about to bring up. If you're using the pre-supplied basebox remember to set the environment variable `VAGRANT_OS="pre-supplied"`.

              ```bash
              $ vagrant up
              Couchbase Server:       http://10.150.150.101:8091/
              Sync Gateway:           http://10.150.150.102:4984/
              Bringing machine 'node1-cb' up with 'virtualbox' provider...
              Bringing machine 'node2-sg' up with 'virtualbox' provider...
              ```

              - You can make a note of the IP addresses in your output, but they should be the same as the ones above. As you might have guessed, we now have two VMs running - one with Couchbase Server and one with Sync Gateway. Let's check the Couchbase Server instance by going to the IP Address and port specified, you should be greeted with this screen:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/welcome_wide.png)

              - That's it, Couchbase Server is now running on this VM. We'll get into configuring it in a minute, but let's take a look at what we did under the covers so that you can replicate this with whatever provisioning tools you prefer (or manually, if you're a purist like that!).

                - The `Vagrantfile` deals with provisioning the VMs themselves. We use the `Vagrantfile` to do some basic processing of download links, but it doesn't actually use these itself; it's more concerned with spinning up the VMs, setting up hostnames and networking and so on. Essentially, when the `Vagrantfile` has done its thing, you're left with a certain number of "clean" VMs.

                - From here, `Puppet` takes over (and is actually kicked off by Vagrant). Puppet handles downloading the Couchbase Server package, and then installing this and making sure the service is running. It also does some other miscellaneous set up to ensure everything is ready to go. You can have a closer look at what's going on in the `cb_puppet.pp` file if you're interested.

                - If you're more than a little bit interested, check out our full repo of Vagrants at https://github.com/couchbaselabs/vagrants - these can be really handy when testing various configurations. It's worth noting though that although the repo is actively maintained, it's provided as-is and is not a supported product in it's own right. PRs are very welcome though!

          - title: Sync Gateway
            description: |
              Sync Gateway is the middleman server that exposes a database API for Couchbase Lite databases to replicate to and from. It connects internally to a Couchbase Server bucket to persist the documents. Again, in a production environment you would connect it to Couchbase Server, but for now let's have a quick look at the one we just started.

              ## Connect to Sync Gateway

              - We already started the VM in the last step, and in the same way `cb_puppet.pp` is used to install and start Couchbase Server, `sg_puppet.pp` was used for this VM to install and start Sync Gateway. We can check this easily either by using `curl`:

                ```bash
                $ curl http://10.150.150.102:4984/

                {"couchdb":"Welcome","vendor":{"name":"Couchbase Sync Gateway","version":1.5},"version":"Couchbase Sync Gateway/1.5.0(594;e78dbf1)"}
                ```

              or by either opening the URL in a browser:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/sg_browser.png)

              - Although we still need to configure Sync Gateway to connect to Couchbase Server, it's already running with the default config. That includes an in memory (`walrus:`) database called `db`. We can have a quick play with this to confirm everything is working as expected.

                - First, check the database is really there:

                  ```bash
                  $ curl http://10.150.150.102:4984/db/

                  {"committed_update_seq":1,"compact_running":false,"db_name":"db","disk_format_version":0,"instance_start_time":1507203061736649,"purge_seq":0,"state":"Online","update_seq":1
                  ```

                - Now let's check the changes feed:

                  ```bash
                  $ curl http://10.150.150.102:4984/db/_changes

                  {"results":[
                  {"seq":1,"id":"_user/","changes":[{"rev":""}]}
                  ],
                  "last_seq":"1"}
                  ```

                - Not too much there yet, but we can easily add some documents:

                  ```bash
                  $ curl -X PUT http://10.150.150.102:4984/db/test_doc -d '{"I am a document": "with a specific name"}' -H 'Content-type: application/json'

                  {"id":"test_doc","ok":true,"rev":"1-838820c27155617e58bef130c14a844a"}
                  ```

                  ```bash
                  $ curl -X POST http://10.150.150.102:4984/db/ -d '{"I am a document": "without a specific name", "could I please have": "a UUID?"}' -H 'Content-type: application/json'

                  {"id":"d6e43b47392ca2e7941744931c250f51","ok":true,"rev":"1-71abb654c47904d0965ff5f1f6fafa72"}
                  ```

                  ```bash
                  $ curl http://10.150.150.102:4984/db/_changes?include_docs=true

                  {"results":[
                  {"seq":1,"id":"_user/","changes":[{"rev":""}]}
                  ,{"seq":2,"id":"test_doc","doc":{"I am a document":"with a specific name","_id":"test_doc","_rev":"1-838820c27155617e58bef130c14a844a"},"changes":[{"rev":"1-838820c27155617e58bef130c14a844a"}]}
                  ,{"seq":3,"id":"d6e43b47392ca2e7941744931c250f51","doc":{"I am a document":"without a specific name","_id":"d6e43b47392ca2e7941744931c250f51","_rev":"1-71abb654c47904d0965ff5f1f6fafa72","could I please have":"a UUID?"},"changes":[{"rev":"1-71abb654c47904d0965ff5f1f6fafa72"}]}
                  ],
                  "last_seq":"3"}
                  ```

              - You'll notice that Sync Gateway's Admin Port (`4985`) isn't accessible:

                ```bash
                $ curl http://10.150.150.102:4985
                curl: (7) Failed to connect to 10.150.150.102 port 4985: Connection refused
                ```

                This is because, by default, the port is only accessible from `localhost` - in this case the VM. Don't worry, we'll change that when we come to configure it to make life easier.

      - title: Configure
        milestones:
          - title: Configuring Couchbase Server
            description: |
              Now that we've got a VM running Couchbase Server, we need to configure it. There are a few options here, we can use the UI, the [REST API](https://developer.couchbase.com/documentation/server/5.0/rest-api/rest-intro.html), or the [CLI](https://developer.couchbase.com/documentation/server/5.0/cli/cli-intro.html). Let's start by looking at the UI as it gives a good sense of what we're doing and why.

              ## Initialise a Couchbase Server Cluster

              - Open the UI in a browser (as you did when you first started the cluster) and select **Setup New Cluster**.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/welcome_focus.png)

              - The next step is pretty self explanatory. You don't need to worry too much about the cluster name, but we'll be needing the credentials later. All the examples here are going to use `Administrator` and `password`, so use these yourself if you want to be able to copy and paste. If you're using Couchbase Mobile for anything more sensitive than this workshop, maybe try something a bit more secure!

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/cluster_init.png)

              - For the next step, you'll need to accept the Terms and Conditions, and then click **Configure Disk, Memory, Services** (we don't want the defaults in this case).

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/terms_conditions.png)

              - On this page, we want to to disable the Index, Search, and Query Services. We don't need them for now, but there's always the opportunity to add them to the cluster later. As well as this, we want to copy in the Public Address. Everything else is fine as it is - hit **Save & Finish**.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/node_init_aws.png)

              ## Create a Bucket

              - Welcome to the Couchbase Server UI! You can see at the moment we have one node running the Data Service, and not much else going on - so let's add a bucket. Click **Buckets** on the left hand bar, then **ADD BUCKET** in the top right corner. In this case, we'll call our bucket `todo` and stick with the defaults for everything else. You can of course pick a different name for your bucket, but be aware that some of the examples in later lessons may need tweaking to match.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/main_ui.png)

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/bucket_init.png)

              ## Create a User

              - With the bucket created, the last bit of configuration we need to do on the Couchbase Server side is to create a user that Sync Gateway will authenticate with. That might sound like a bit of a strange concept - this isn't front end user, it's just going to be used by Sync Gateway itself. Starting in Couchbase Server 5.0, [Role Based Access Control](https://developer.couchbase.com/documentation/server/5.0/security/security-authorization.html#authorization) is used to control access to all features and functions of the cluster, Sync Gateway therefore needs to authenticate against Couchbase Server just like any other client would. Click **Security** in the left hand bar, then **ADD USER** in the top right corner. We want to use `Couchbase` as the **Authentication Domain** in this workshop. As with the Administrator credentials, you can pick anything here, but if you want to copy and paste the credentials we will be using are `sg_user` and `rb4c_p4ssw0rd`.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/rbac_user.png)

              - As for the roles themselves, we want to give `sg_user` the **Bucket Full Access** role for the `todo` bucket.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/rbac_role.png)
          - title: Configuring Sync Gateway
            description: |
              Previously, we were able to access the Sync Gateway VM we set up and perform some CRUD operations against it; however we were only using a local, in-memory `walrus` instance as the back-end. Now that we've got Couchbase Server set up, let's configure Sync Gateway to connect directly to it.

              ## Check the Current Config

              - First we need to ssh into the VM running Sync Gateway - Vagrant makes this as easy as running one command:

                ```bash
                $ vagrant ssh node2-sg
                Sync Gateway:           http://10.150.150.102:4984/
                [vagrant@node2-centos7 ~]$
                ```

              - Once we're ssh'd in, we can first see the Admin API for the first time:

                ```bash
                $ curl localhost:4985

                {"ADMIN":true,"couchdb":"Welcome","vendor":{"name":"Couchbase Sync Gateway","version":1.5},"version":"Couchbase Sync Gateway/1.5.0(594;e78dbf1)"}
                ```

              - With this API, we can check the current running config:

                ```bash
                $ curl localhost:4985/_config
                ```

                The output might be a bit awkward to read, but pretty-printed it should look something like this:

                ```json
                {
                  "Interface": "0.0.0.0:4984",
                  "AdminInterface": "127.0.0.1:4985",
                  "log": [
                    "HTTP+"
                  ],
                  "Databases": {
                    "db": {
                      "server": "walrus:data",
                      "pool": "default",
                      "bucket": "db",
                      "name": "db",
                      "users": {
                        "GUEST": {
                          "name": "",
                          "admin_channels": [
                            "*"
                          ],
                          "all_channels": null
                        }
                      }
                    }
                  }
                }
                ```

              ## Add a New Database

              - In the config we can see that there is one Sync Gateway database defined: `db`. Let's add another! We could use the Admin REST API for this, but we really want the config to persist across reboots, so it's better to edit the config file on disk at `/home/sync_gateway/sync_gateway.json`. By default the VM won't have much choice in terms of editors, so if you'd rather not use `vi`, feel free to install something you're more comfortable with - the `vagrant` user you're logged in as will have passwordless `sudo` access.

                `sync_gateway.json` will have a very similar structure to the output of the `_config` endpoint, but with fewer entries (many are added as defaults at runtime). We just need to add another database under the `databases` property. All the properties here should be reasonable self explanatory, but you can find the full list of options and descriptions in [our documentation](https://developer.couchbase.com/documentation/mobile/current/guides/sync-gateway/config-properties/index.html):

                ```json
                "todo": {
                  "server": "http://10.150.150.101:8091",
                  "bucket": "todo",
                  "username": "sg_user",
                  "password": "rb4c_p4ssw0rd",
                  "users": {
                    "GUEST": {"disabled": false, "admin_channels": ["*"] }
                  },
                  "import_docs": "continuous",
                  "enable_shared_bucket_access": true
                }
                ```

                The last two settings (`import_docs` and `enable_shared_bucket_access`) allow us to take advantage of the new features in Couchbase Server 5.0 and Sync Gateway 1.5. In short, this lets you use the [Couchbase SDKs](https://developer.couchbase.com/documentation/server/4.6/sdk/development-intro.html) to access the same data seamlessly.

                While we're here, let's up the logging output to `*` so we can see more of what's going on in the logs:

                ```json
                "log": ["*"]
                ```

                And also make the Admin API accessible externally:

                ```json
                "adminInterface": "0.0.0.0:4985"
                ```

                Before saving, it's worth double-checking that the file is valid json - commas in particular! `python` has a nice way of doing this inside the VM - any errors will look something like this:

                ```bash
                $ sudo python -m json.tool /home/sync_gateway/sync_gateway.json
                Expecting , delimiter: line 3 column 2 (char 17)
                ```

              ## Load the New Config

              - With the config file updated and syntax error free, we need to restart Sync Gateway to pick it up:

                ```bash
                $ sudo service sync_gateway restart
                ```

                Now when we check the `_config` endpoint, we should see the new database included:

                ```bash
                $ curl localhost:4985/_config -sS | python -m json.tool
                {
                    "AdminInterface": "0.0.0.0:4985",
                    "Databases": {
                        "db": {
                            "bucket": "db",
                            "name": "db",
                            "pool": "default",
                            "server": "walrus:data",
                            "users": {
                                "GUEST": {
                                    "admin_channels": [
                                        "*"
                                    ],
                                    "all_channels": null,
                                    "name": ""
                                }
                            }
                        },
                        "todo": {
                            "bucket": "todo",
                            "name": "todo",
                            "password": "rb4c_p4ssw0rd",
                            "pool": "default",
                            "server": "http://10.150.150.101:8091",
                            "username": "sg_user",
                            "users": {
                                "GUEST": {
                                    "admin_channels": [
                                        "*"
                                    ],
                                    "all_channels": null,
                                    "name": ""
                                }
                            }
                        }
                    },
                    "Interface": "0.0.0.0:4984",
                    "log": [
                        "*"
                    ]
                }
                ```

              - We can confirm this in a couple of places. Firstly, we can see that there's now a collection of `/todo/` endpoints (although not much in there yet):

                ```bash
                $ curl localhost:4984/todo/_all_docs
                {"rows":[
                ],
                "total_rows":0,"update_seq":1}
                ```

                We can also check and see that Sync Gateway has connected to Couchbase Server. If you go to the **Buckets** section, you can click **Documents** to view the contents of the `todo` bucket.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/todo_bucket.png)

                Here you should now see a handful of documents holding Sync Gateway's metadata:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/todo_docs.png)

              Congratulations! Sync Gateway is now configured with a Couchbase Server back-end. At this point, you can start connecting apps and persisting the data to Couchbase Server. You've got the basis to build a robust production deployment - more about that in the next lesson!

      - title: Scale
        milestones:
          - title: Scaling Couchbase Server
            description: |
              Having one Couchbase Server node is all well and good, but for High Availability and improved performance, you'll need a cluster.
              Couchbase Server is designed to make this scaling incredibly easy; all you need are a few extra VMs running Couchbase Server and you can scale out the cluster straight from the UI.

              - First, we'll need some more nodes. If you've been looking over the `Vagrantfile` you might have noticed there are a few spare nodes mentioned:

                ```bash
                $ vagrant status
                Couchbase Server:       http://10.150.150.101:8091/
                Sync Gateway:           http://10.150.150.102:4984/
                Couchbase Server:       http://10.150.150.103:8091/
                Couchbase Server:       http://10.150.150.104:8091/
                Sync Gateway:           http://10.150.150.105:4984/
                NGINX :                 http://10.150.150.106:4984/
                Current machine states:

                node1-cb                  running (virtualbox)
                node2-sg                  running (virtualbox)
                node3-cb                  not created (virtualbox)
                node4-cb                  not created (virtualbox)
                node5-sg                  not created (virtualbox)
                node6-nginx               not created (virtualbox)

                This environment represents multiple VMs. The VMs are all listed
                above with their current state. For more information about a specific
                VM, run `vagrant status NAME`.
                ```

              - So we've got a couple of spare Couchbase Server nodes - let's spin those up. Unlike before, we will need to specify these by name:

                ```bash
                $ vagrant up node3-cb node4-cb
                Couchbase Server:       http://10.150.150.103:8091/
                Couchbase Server:       http://10.150.150.104:8091/
                Bringing machine 'node3-cb' up with 'virtualbox' provider...
                Bringing machine 'node4-cb' up with 'virtualbox' provider...
                ```

                Once this completes, you should see the familiar UI at either of those URLs:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/welcome_focus.png)

              ## Join the Cluster with a New Node

              - For the first node, let's add it to the cluster from here. First (as you might have guessed), click **Join Existing Cluster**. Here we want to specify the first node, which is the only node so far in the cluster we want to join, and the Administrator credentials we set earlier (`Administrator`, `password` if you're following along):

               ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/join_cluster.png)

              - Before we click through, we also want to only have the Data Service running on this node, we can do this in the same way we did last time under the **Configure Services & Settings For This Node** section:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/join_cluster_detail.png)

              - Finally, click **Join With Custom Configuration**. You should be greeted with a very familiar UI, only now with 2 nodes:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/joined_cluster.png)

              - It's worth noting at this point that you can access and administer the cluster from any of the nodes - you'll notice we're still on the second node.

              ## Add a Third Node to the Cluster

              - We've got one more node to add, let's do it from the cluster itself, rather than from the new node. Click the **Servers** section on the left hand bar, and you can now see the last node we added:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/pending_rebalance.png)

                As the message suggests, this needs Rebalancing into the cluster before it starts taking traffic, but let's wait until we've got both nodes ready before starting the rebalance.

              - In the top right corner, click **ADD SERVER** and then fill in the Public Address of the last node. As this node has not been initialised yet, it doesn't actually have Administrator credentials and we can ignore this. Again, let's add only the Data Service and finally click **Add Server**:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/add_node.png)

              ## Rebalance the Cluster

              - Finally, start a rebalance with the **Rebalance** button and watch it progress.

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/rebalancing.png)

              - The key thing to note here is that everything is totally online. All data is available during the rebalance.

          - title: Scaling Sync Gateway
            description: |
              As with Couchbase Server, having one Sync Gateway running is fine, but you'll eventually want to scale out to ensure you have High Availability for a production deployment. Because of the way they're deployed and the functions they serve, Couchbase Server and Sync Gateway scale in different ways. Scaling Sync Gateway requires a Load Balancer in front of it, but as Sync Gateway is essentially stateless we don't need to worry about adding it to a cluster - only adding it behind the Load Balancer.

              ## Configure the New Sync Gateway

              - As you might've noticed in the last section, there's a spare Sync Gateway node just waiting to be provisioned. Before we get to that though, it's worth considering configuration again. Because unlike Couchbase Server, Sync Gateway is not inherently clustered, we need to make sure that the same configuration is used on each node. If you've looked over `sg_puppet.pp`, you might've seen this section:

                ```ruby
                # Copy config if one supplied
                exec { "sync_gateway-config":
                    command => "/bin/cp /vagrant/sync_gateway.json /home/sync_gateway/sync_gateway.json",
                    returns => [0,1],
                    notify => Service["sync_gateway"],
                    require => Package["sync_gateway"]
                }
                ```

                Essentially this will copy in a supplied `sync_gateway.json` and restart Sync Gateway during the provisioning process. This gets copied from the `/vagrant/` directory inside the VM - this directory is actually mapped directly to the host's directory that the Vagrant was started from. This gives us an opportunity to save some time.

              - If we ssh into the current running Sync Gateway node, we can copy out the config we already modified in the last lesson:

                ```bash
                $ vagrant ssh node2-sg

                [vagrant@node2-centos7 ~]$ sudo cp /home/sync_gateway/sync_gateway.json /vagrant/
                ```

                Now the next node we spin up will pull in this config automatically.

              - Now it's just a simple matter of running `vagrant up` on the new Sync Gateway node:

                ```bash
                $ vagrant up node5-sg
                Sync Gateway:           http://10.150.150.105:4984/
                Bringing machine 'node5-sg' up with 'virtualbox' provider...
                ```

              - Now, unlike last time, we should be able to access the Admin port directly as we enabled it in the config that got copied across.

                ```bash
                $ curl 10.150.150.105:4985

                {"ADMIN":true, ...
                ```

              ## Load Balancing

              In theory, we could stop here - we've got two Sync Gateways connected to the same Couchbase Server cluster. For some deployments, this might actually be preferable so you can manually partition your traffic by pointing apps at different Sync Gateways (particularly if you're deploying Couchbase Lite in a handful of static locations). For most deployments though, you'll want to be able to dynamically partition traffic across your Sync Gateway nodes - this is where a Load Balancer comes in.

              - There's one final Vagrant that we haven't touched yet - and you might've guessed from the name what it does. Before we spin it up though, let's take a look at `nginx_puppet.pp`. Just like `sg_puppet.pp`, there's a section that copies in a config file and restarts the service:

                ```ruby
                # Copy config if one supplied
                exec { "sync_gateway-config":
                    command => "/bin/cp /vagrant/nginx.conf /etc/nginx/conf.d/sync_gateway_nginx.conf",
                    returns => [0,1],
                    notify => Service["nginx"],
                    require => Package["nginx"]
                }
                ```

              - Let's have a look at `nginx.conf` to see what we're copying in. First, we've got the list of upstream servers, which currently only has the first Sync Gateway node:

                ```nginx
                upstream sync_gateway {
                  server 10.150.150.102:4984;
                }
                ```

                Let's add the second Sync Gateway node in:

                ```nginx
                upstream sync_gateway {
                  server 10.150.150.102:4984;
                  server 10.150.150.105:4984;
                }
                ```

                This allows NGINX to balance requests between the two nodes.

                The rest of the file deals with how we want NGINX to proxy the requests generally, whether that's to one server or many. It's a little outside the scope of this workshop, but you can find more details in our [documentation](https://developer.couchbase.com/documentation/mobile/current/guides/sync-gateway/nginx/index.html).

              - With `nginx.conf` updated and saved, we can now spin up the final VM as we have for the others:

                ```bash
                $ vagrant up node6-nginx
                NGINX :                 http://10.150.150.106:4984/
                Bringing machine 'node6-nginx' up with 'virtualbox' provider...
                ```

              - Once this is complete, you should be able to make requests to the NGINX VM as though it were Sync Gateway:

                ```bash
                $ curl 10.150.150.106:4984/todo/_changes
                {"results":[
                {"seq":1,"id":"_user/GUEST","changes":[]}
                ],
                "last_seq":"1"}
                ```

      - title: Extra Credit
        milestones:
          - title: Adding more Couchbase Services
            description: |
              When we scaled out the Couchbase Server cluster, we only used the Data Service, because it was all we really needed. For a production deployment, this is actually what we'd recommend - separating the services to dedicated nodes helps you more easily achieve redundancy for each service as well as letting you scale each service separately as your workload and use case demands. There are a couple of ways we could add more services to this cluster: removing a node and re-adding it with more services enabled; or adding yet more nodes.

              - There's a hidden option in the Vagrantfile to provision yet more nodes, so let's take advantage of that:

                ```bash
                $ export VAGRANT_CB_EXTRA_NODES=1
                $ vagrant status
                Couchbase Server:       http://10.150.150.101:8091/
                Sync Gateway:           http://10.150.150.102:4984/
                Couchbase Server:       http://10.150.150.103:8091/
                Couchbase Server:       http://10.150.150.104:8091/
                Sync Gateway:           http://10.150.150.105:4984/
                NGINX :                 http://10.150.150.106:4984/
                Couchbase Server:       http://10.150.150.107:8091/
                Current machine states:

                node1-cb                  running (virtualbox)
                node2-sg                  running (virtualbox)
                node3-cb                  running (virtualbox)
                node4-cb                  running (virtualbox)
                node5-sg                  running (virtualbox)
                node6-nginx               running (virtualbox)
                node7-cb                  not created (virtualbox)
                ```

              - Voilà! We've got an extra Couchbase Server node. Let's bring it up and add it to the cluster. This time, let's use the REST API to add it into the cluster.

                ```bash
                $ vagrant up node7-cb
                Couchbase Server:       http://10.150.150.107:8091/
                Bringing machine 'node7-cb' up with 'virtualbox' provider...
                ```

                ```bash
                $ curl -u Administrator:password 10.150.150.101:8091/controller/addNode -d 'hostname=10.150.150.107' -d 'services=index,n1ql,fts' -d 'user=Administrator' -d 'password=password'

                {"otpNode":"ns_1@10.150.150.107"}
                ```

              - Now we just need to start a rebalance. We could do this again through the [REST API](https://developer.couchbase.com/documentation/server/4.6/rest-api/rest-cluster-rebalance.html), or through the UI like we have before.

              - Once the rebalance is complete, you can open the [Query tab](http://10.150.150.107:8091/ui/index.html#!/query/workbench) in a browser to access the [Query Workbench](https://developer.couchbase.com/documentation/server/5.0/tools/query-workbench.html) on the new node.

          - title: Deploying the Develop Section
            description: |
              In the Develop section of the workshop, you created and *"deployed"* a full Couchbase Mobile app. Let's change "deployed" into Deployed and actually deploy this into a production ready environment.

              Luckily, we've already covered most of the steps for this. At a high level, these are:

              - Load the `travel-sample` bucket on the Couchbase Server cluster.
              - Create a Sync Gateway database that points to the `travel-sample` bucket.
              - Update the app to point to the new Sync Gateway (or, more precisely, Sync Gateways via the Load Balancer)

              There are a few caveats here, and things we haven't covered. Depending on how you performed the previous steps, you might encounter a few complexities in your environment:

              ## Server Quotas, Bucket Quotas, and Other Numbers

              You may recall when we first initialised the cluster, we set a quota for the Data Service:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/node_init_aws.png)

              - This sets the upper limit for the total quota of every bucket in the cluster. When we created the `todo` bucket, we used up all of this quota with the one bucket, so we have nothing left for `travel-sample`. There are a couple of ways to approach this problem:

                - Delete the `todo` bucket and associated Sync Gateway database.
                - Adjust `todo`'s quota and add `travel-sample` alongside it.

              To do either of these, we need to go to the **Buckets** page in the Couchbase Server UI and click on the `todo` bucket. From here we have the option to **Delete** or **Edit** the bucket:

                ![](https://raw.githubusercontent.com/couchbaselabs/mobile-travel-sample/connect_sv/content/deploy/assets/bucket_detail.png)

              - The choice is yours, and this being the Extra Credit section, we'll be a bit more sparse with the instructions - we believe in you! (Do feel free to ask though!)

              ## A New Database

              - Either way, you'll need to update the Sync Gateway config file to add the new database. Again, we're sure you can manage to add in the database from the [config file used in Develop](https://github.com/couchbaselabs/mobile-travel-sample/blob/connect_sv/sync-gateway-config-travelsample.json) but do ask if you have questions! Be sure to either set up a user in Couchbase Server that has access to the correct bucket - either by adding this permission to the `sg_user` user we used previously, or by creating a new user for this new bucket and database.

              - Once this is updated, and pointing to the correct Couchbase Server cluster with all the correct permissions, we need to have each Sync Gateway load this new config. We did this in a slightly different way before - using Puppet to automatically load the new config as we bring a node up. We could destroy the nodes and recreate them, having updated the config file on the host (`$ vagrant destroy node2-sg node5-sg && vagrant up node2-sg node5-sg`); but it's more lightweight to simply ssh into each instance in turn, update the config, and restart the Sync Gateway as we did the first time we changed the config.

              - With more of a production focus, you may well want to utilise a load balancer in front of Sync Gateway to implement the change over, ensuring that at any one time requests are only getting routed to one particular version of the config. You want to avoid a situation where a load balancer may route alternate requests to different Sync Gateways with different configs!
      - title: Upgrade
        milestones:
          - title: Sync Gateway 1.4/Couchbase Server 4.6
            description: |
              In this section of the workshop, we will perform a rolling upgrade to the latest release. To start with a running cluster, we will install the previous versions of Sync Gateway (1.4.1) and Couchbase Server (4.6) on the various VMs. Then from there, we will go through each step to upgrade the system to Sync Gateway (1.5) and Couchbase Server (5.0) with minimal downtime incurred on the applications.
              
              The [compatibility matrix](https://developer.couchbase.com/documentation/mobile/1.5/installation/index.html) lists the versions that can be used between Couchbase Lite, Sync Gateway and Couchbase Server. Mobile clients running previous versions of Couchbase Lite will continue to synchronize with Sync Gateway 1.5.
              
              Once the upgrade is completed, you may also wish to enable the new replication protocol which is currently in developer preview in Sync Gateway 1.5 (see the Couchbase Lite 2.0 [replication guide](https://developer.couchbase.com/documentation/mobile/2.0/guides/couchbase-lite/native-api/replication/index.html)).
              
              ## Install Sync Gateway 1.4/Couchbase Server 4.6
              
              If you've followed the previous sections, you will first need to stop the running VMs.
              
              ```bash
              $ vagrant destroy node1-cb node2-sg node3-cb node4-cb node5-sg node6-nginx
              ```
              
              In order to re-provision an earlier version, open **Vagranfile** and update the `CB_VERSION` and `SG_VERSION` constants with the following:
              
              ```bash
              CB_VERSION = "4.6.3"
              SG_VERSION = "1.4.1-3"
              ```
              
              Save your edits. Next, let's re-provision NGINX, Sync Gateway and Couchbase Server on each VM respectively.
              
              ```bash
              $ vagrant up node1-cb node2-sg node3-cb node4-cb node5-sg node6-nginx
              ```
              
              SSH into **node1-cb** and initialize Couchbase Server.
              
              ```bash
              $ vagrant ssh node1-cb
              [node1] $ /opt/couchbase/bin/couchbase-cli cluster-init \
                          -c 127.0.0.1 \
                          --cluster-init-username=Administrator \
                          --cluster-init-password=password \
                          --cluster-init-ramsize=500 \
                          -u Administrator -p password \
                          --services data,index,query \
                          --cluster-index-ramsize 256
              ```
              
              Open [http://10.150.150.101:8091/](http://10.150.150.101:8091/) in a browser and log in with the credentials used above (**Administrator** and **password**). Next, you'll need to create a new bucket with the travel data. Select the **Settings > Sample Buckets**, check the **travel-sample** box and click **Create**.
              
              ![](https://cl.ly/0T1E2j1R2G2H/Screen%20Shot%202017-11-08%20at%2016.42.34.png)
              
              Return to the **Data Buckets** screen and set a bucket password on the **travel-sample** bucket.
              
              ![](https://cl.ly/413E1H3E393i/edit-bucket.png)
              
              In this example, we're using "password" as the password.
              
              ![](https://cl.ly/0U2Z061I193b/set-password.png)
              
              Return to the **node1-cb** SSH prompt and add **node3-cb** and **node4-cb**.
              
              ```bash
              [node1-cb] $ /opt/couchbase/bin/couchbase-cli server-add \
                  -c 127.0.0.1 \
                  -u Administrator \
                  -p password \
                  --server-add 10.150.150.103:8091 \
                  --server-add-username Administrator \
                  --server-add-password password \
                  --services data
              
              [node1-cb] $ /opt/couchbase/bin/couchbase-cli server-add \
                  -c 127.0.0.1 \
                  -u Administrator \
                  -p password \
                  --server-add 10.150.150.104:8091 \
                  --server-add-username Administrator \
                  --server-add-password password \
                  --services data
              ```
              
              Run the rebalance command to include the 2 additional Couchbase Server nodes in the cluster.
              
              ```bash
              [node1-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                  -c 127.0.0.1 \
                  -u Administrator \
                  -p password
              ```
              
              This may take a few minutes. Once the rebalance has completed, you can open [http://10.150.150.101:8091/ui/index.html#/servers/active](http://10.150.150.101:8091/ui/index.html#/servers/active) and all 3 nodes should be displayed on the UI.
              
              ![](https://cl.ly/1o1t3c02370g/Screen%20Shot%202017-11-09%20at%2013.53.00.png)
              
              Next, you will setup the 2 Sync Gateway nodes. SSH onto **node2-sg** and open the configuration file located under **/home/sync_gateway/sync_gateway.json**.
              
              ```bash
              $ vagrant ssh node2-sg
              [node2-sg] $ sudo vi /home/sync_gateway/sync_gateway.json
              ```
              
              Replace its content with the following.
              
              ```bash
              {
                "log": ["HTTP+"],
                "adminInterface": "127.0.0.1:4985",
                "interface": "0.0.0.0:4984",
                "databases": {
                  "travel-sample": {
                    "server": "http://10.150.150.101:8091",
                    "bucket": "travel-sample",
                    "user": "travel-sample",
                    "password": "password",
                    "import_docs": true,
                    "users": {
                      "GUEST": {"disabled": false, "admin_channels": ["*"] }
                    }
                  }
                }
              }
              ```
              
              The documents imported from the **travel-sample** bucket do not contain any of the mobile `_sync` metadata. So we are using the `import_docs` property to generate that metadata for each document already present in the bucket. Notice also the presence of the `user` and `password` properties, without those credentials, the Sync Gateway node can't access the data in the bucket.
              
              Restart the Sync Gateway service.
              
              ```bash
              [node2-sg] $ sudo systemctl restart sync_gateway
              ```
              
              At this point, Sync Gateway will be processing all the documents and thus won't be accessible during that time (it could take up to 5 minutes as there are 35 000 documents in the bucket). Use the following command to monitor the logs.
              
              ```bash
              [node2-sg] $ sudo tail -n 50 -f /home/sync_gateway/logs/sync_gateway_error.log
              
              ...
              2017-11-09T13:05:16.139Z Re-running sync function on all 31591 documents...
              ```
              
              The log message above indicates that Sync Gateway is busy processing all documents. Once it has completed, you will see the following in the logs.
              
              ```bash
              2017-11-09T13:09:08.708Z Finished re-running sync function; 31591 docs changed
              ```
              
              Open [http://10.150.150.102:4984/travel-sample/_all_docs?limit=10](http://10.150.150.102:4984/travel-sample/_all_docs?limit=10) to make sure the import process ran successfully.
              
              Repeat the same steps for **node5-sg**.
              
              ```bash
              $ vagrant ssh node5-sg
              [node5-sg] $ sudo vi /home/sync_gateway/sync_gateway.json
              ```
              
              With the following configuration file:
              
              ```bash
              {
                "log": ["HTTP+"],
                "adminInterface": "127.0.0.1:4985",
                "interface": "0.0.0.0:4984",
                "databases": {
                  "travel-sample": {
                    "server": "http://10.150.150.101:8091",
                    "bucket": "travel-sample",
                    "user": "travel-sample",
                    "password": "password",
                    "users": {
                      "GUEST": {"disabled": false, "admin_channels": ["*"] }
                    }
                  }
                }
              }
              ```
              
              We are not using the `import_docs` property on **node5-sg** anymore because that task was already done by **node2-sg**. Restart the service.
              
              ```bash
              [node5-sg] $ sudo systemctl restart sync_gateway
              ```
              
              Once completed, open [http://10.150.150.105:4984/travel-sample/_all_docs?limit=10](http://10.150.150.105:4984/travel-sample/_all_docs?limit=10) to check the same documents are accessible through the Sync Gateway REST API of **node5-sg**.
              
              Next, you will update the load balancer configuration. SSH into **node6-nginx** and open the NGINX config file.
              
              ```bash
              $ vagrant ssh node6-nginx
              [node6-nginx] $ sudo vi /etc/nginx/conf.d/sync_gateway_nginx.conf
              ```
              
              Update the config the IP address of **node5-sg**.
              
              ```bash
              upstream sync_gateway {
                server 10.150.150.102:4984;
                server 10.150.150.105:4984;
              }
              ```
              
              Restart the NGINX service.
              
              ```bash
              [node6-nginx] $ sudo systemctl restart nginx
              ```
              
              Open [http://10.150.150.106:4984/travel-sample/_all_docs?limit=10](http://10.150.150.106:4984/travel-sample/_all_docs?limit=10) to verify that the same 10 documents queried previously are accessible through NGINX.
              
              Congratulations! You have successfully deployed Sync Gateway 1.4.1 and Couchbase 4.6 on vagrant VMs. In the next section you will begin the rolling upgrade to Sync Gateway 1.5 and Couchbase Server 5.0.
          - title: Sync Gateway 1.5
            description: |
              ## Upgrade Sync Gateway
              
              SSH into **node2-sg** and update this VM to use Sync Gateway 1.5.
              
              ```bash
              $ vagrant ssh node2-sg
              [node2-sg] $ sudo rpm -e couchbase-sync-gateway-1.4.1-3.x86_64
              [node2-sg] $ wget https://packages.couchbase.com/releases/couchbase-sync-gateway/1.5.0/couchbase-sync-gateway-enterprise_1.5.0_x86_64.rpm
              [node2-sg] $ sudo rpm -i couchbase-sync-gateway-enterprise_1.5.0_x86_64.rpm
              ```
              
              Open the configuration file.
              
              ```bash
              [node2-sg] $ sudo vi /home/sync_gateway/sync_gateway.json
              ```
              
              Update the configuration to use the following.
                            
              ```bash
              {
                "log": ["HTTP+"],
                "adminInterface": "127.0.0.1:4985",
                "interface": "0.0.0.0:4984",
                "databases": {
                  "travel-sample": {
                    "server": "http://10.150.150.101,10.150.150.103,10.150.150.104:8091",
                    "bucket": "travel-sample",
                    "user": "travel-sample",
                    "password": "password",
                    "users": {
                      "GUEST": {"disabled": false, "admin_channels": ["*"] }
                    }
                  }
                }
              }
              ```
              
              Note that we are specifying multiple Couchbase Server URLs in this config, that's a new feature that was introduced in Sync Gateway 1.5. But we haven't enabled the shared bucket access feature introduced in Sync Gateway 1.5 yet. We will first need to upgrade Couchbase Server to 5.0 in order to do so.
              
              Restart the Sync Gateway service.
              
              ```bash
              [node2-sg] $ sudo systemctl restart sync_gateway
              ```
              
              Query the NGINX endpoint on [http://10.150.150.106:4984](http://10.150.150.106:4984), you should notice that the `version` returned in the JSON response switches between `1.4` and `1.5` as you refresh the browser window.
              
              Repeat the same steps to upgrade Sync Gateway to 1.5 on **node5-sg**.
              
              ```bash
              $ vagrant ssh node5-sg
              [node5-sg] $ sudo rpm -e couchbase-sync-gateway-1.4.1-3.x86_64
              [node5-sg] $ wget https://packages.couchbase.com/releases/couchbase-sync-gateway/1.5.0/couchbase-sync-gateway-enterprise_1.5.0_x86_64.rpm
              [node5-sg] $ sudo rpm -i couchbase-sync-gateway-enterprise_1.5.0_x86_64.rpm
              [node5-sg] $ sudo vi /home/sync_gateway/sync_gateway.json
              ```
              
              With the following configuration file.
              
              ```bash
              {
                "log": ["HTTP+"],
                "adminInterface": "127.0.0.1:4985",
                "interface": "0.0.0.0:4984",
                "databases": {
                  "travel-sample": {
                    "server": "http://10.150.150.101,10.150.150.103,10.150.150.104:8091",
                    "bucket": "travel-sample",
                    "user": "travel-sample",
                    "password": "password",
                    "users": {
                      "GUEST": {"disabled": false, "admin_channels": ["*"] }
                    }
                  }
                }
              }
              ```
              
              Restart the service.
              
              ```bash
              [node5-sg] $ sudo systemctl restart sync_gateway
              ```
              
              Query the **node5-sg** endpoint on [http://10.150.150.105:4984](http://10.150.150.105:4984) to verify Sync Gateway 1.5 is running.
              
              Congratulations! You have upgraded the Sync Gateway instances to 1.5. In the next section, you will upgrade the Couchbase Server nodes.
              
          - title: Couchbase Server 5.0
            description: |
              ## Upgrade Couchbase Server
              
              In this example, you will run a **Regular Rebalance** to upgrade Couchbase Server. Other upgrade paths can be found in the Couchbase Server [documentation](https://developer.couchbase.com/documentation/server/current/install/upgrade-strategies.html).
              
              First, SSH into **node1-cb** and remove it from the cluster.
              
              ```bash
              $ vagrant ssh node1-cb
              [node1-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                              -c 127.0.0.1 \
                              -u Administrator \
                              -p password \
                              --server-remove 10.150.150.101:8091
              ```
              
              Documents should still be accessible from the NGINX endpoint [http://10.150.150.106:4984/travel-sample/_all_docs?limit=10](http://10.150.150.106:4984/travel-sample/_all_docs?limit=10).
              
              Back in the **node1-cb** command prompt, stop the **couchbase-server** service and upgrade it to Couchbase Server 5.0.
              
              ```bash
              [node1-cb] $ sudo systemctl stop couchbase-server
              [node1-cb] $ sudo rpm -e couchbase-server-4.6.3-4136.x86_64
              [node1-cb] $ wget https://packages.couchbase.com/releases/5.0.0/couchbase-server-community-5.0.0-centos7.x86_64.rpm
              [node1-cb] $ sudo rpm -i couchbase-server-community-5.0.0-centos7.x86_64.rpm
              ```
              
              Add **node1-cb** back to the cluster.
              
              ```bash
              [node1-cb] $ /opt/couchbase/bin/couchbase-cli server-add \
                              -c 10.150.150.103 \
                              -u Administrator \
                              -p password \
                              --server-add 10.150.150.101:8091 \
                              --server-add-username Administrator \
                              --server-add-password password \
                              --services data,index,query
              ```
              
              Rebalance the cluster.
              
              ```bash
              [node1-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                              -c 127.0.0.1 \
                              -u Administrator \
                              -p password
              ```
              
              Open the Console on **node1-cb** at []() and notice the orange banner that points out that the cluster is in **4.6 Compatibility mode**.
              
              ![](https://cl.ly/402n0f2d3v0o/compat-mode.png)
              
              Only 1 out of the 3 Couchbase Server nodes has been updated to 5.0. New features introduced in 5.0 such as RBAC will not be available for use until all nodes have been upgraded (at which point the orange banner will not be shown anymore).
              
              Let's upgrade **node3-cb** and **node4-cb** in the cluster with the following commands.
              
              ```bash
              $ vagrant ssh node3-cb
              [node3-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                              -c 127.0.0.1 \
                              -u Administrator \
                              -p password \
                              --server-remove 10.150.150.103:8091
              [node3-cb] $ sudo systemctl stop couchbase-server
              [node3-cb] $ sudo rpm -e couchbase-server-4.6.3-4136.x86_64
              [node3-cb] $ wget https://packages.couchbase.com/releases/5.0.0/couchbase-server-community-5.0.0-centos7.x86_64.rpm
              [node3-cb] $ sudo rpm -i couchbase-server-community-5.0.0-centos7.x86_64.rpm
              [node3-cb] $ /opt/couchbase/bin/couchbase-cli server-add \
                              -c 10.150.150.101 \
                              -u Administrator \
                              -p password \
                              --server-add 10.150.150.103:8091 \
                              --server-add-username Administrator \
                              --server-add-password password \
                              --services data
              [node3-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                              -c 127.0.0.1 \
                              -u Administrator \
                              -p password
              [node3-cb] $ exit
              
              $ vagrant ssh node4-cb
              [node4-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                              -c 127.0.0.1 \
                              -u Administrator \
                              -p password \
                              --server-remove 10.150.150.104:8091
              [node4-cb] $ sudo systemctl stop couchbase-server
              [node4-cb] $ sudo rpm -e couchbase-server-4.6.3-4136.x86_64
              [node4-cb] $ wget https://packages.couchbase.com/releases/5.0.0/couchbase-server-community-5.0.0-centos7.x86_64.rpm
              [node4-cb] $ sudo rpm -i couchbase-server-community-5.0.0-centos7.x86_64.rpm
              [node4-cb] $ /opt/couchbase/bin/couchbase-cli server-add \
                              -c 10.150.150.101 \
                              -u Administrator \
                              -p password \
                              --server-add 10.150.150.104:8091 \
                              --server-add-username Administrator \
                              --server-add-password password \
                              --services data
              [node4-cb] $ /opt/couchbase/bin/couchbase-cli rebalance \
                              -c 127.0.0.1 \
                              -u Administrator \
                              -p password
              [node4-cb] $ exit
              ```
              
              At this point, you should see the 3 nodes in Console UI [http://10.150.150.101:8091/ui/index.html#!/servers/list](http://10.150.150.101:8091/ui/index.html#!/servers/list) as you did previously before the upgrade.
              
              ![](https://cl.ly/0k472s1a3F0m/post-cbs-upgrade.png)
              
              Notice that the **4.6 compatibility mode** isn't being displayed anymore. On the **Security** tab, a new user was automatically created with **travel-sample** as the username and **password** as the password (see [Legacy Buckets on the Standard Port](https://developer.couchbase.com/documentation/server/5.0/security/security-rbac-upgrade.html#story-h2-3)). Those correspond to the bucket name and bucket password that was set previously in the 4.6 version of the cluster.
              
              We used those same credentials in the Sync Gateway configuration file previously, thus Sync Gateway continues to have access to the bucket as the **travel-sample**/**password** user. You can verify this by opening [http://10.150.150.106:4984/travel-sample/_all_docs?limit=10](http://10.150.150.106:4984/travel-sample/_all_docs?limit=10) in a browser window.
              
              Congratulations! You've successfully upgraded all 3 Couchbase Server nodes to 5.0. In the next section, you will enabled the shared bucket access feature introduced in Sync Gateway 1.5.
          - title: Shared Access
            description: |
              ## Enable Bucket Shared Access
            
              To enable the shared bucket access between Couchbase Mobile, N1QL and Server SDKs we will update the Sync Gateway configuration on both Sync Gateway instances.
              
              First, we will need to run an import process on all the documents to migrate over the `_sync` document metadata currently embedded in the document body to the extended attributes which is a new feature that was introduced in Couchbase Server 5.0.
              
              SSH into **node2-sg** to edit the configuration file.
              
              ```bash
              $ vagrant ssh node2-sg
              [node2-sg] $ sudo vi /home/sync_gateway/sync_gateway.json
              ```
              
              Update the configuration file with the following.
              
              ```bash
              {
                "log": ["HTTP+", "Import+"],
                "adminInterface": "127.0.0.1:4985",
                "interface": "0.0.0.0:4984",
                "databases": {
                  "travel-sample": {
                    "server": "http://10.150.150.101,10.150.150.103,10.150.150.104:8091",
                    "bucket": "travel-sample",
                    "user": "travel-sample",
                    "password": "password",
                    "import_docs": "continuous",
                    "enable_shared_bucket_access": true,
                    "users": {
                      "GUEST": {"disabled": false, "admin_channels": ["*"] }
                    }
                  }
                }
              }
              ```
              
              We introduced two new properties here. You can follow the links below to understand what each one does:
              
              - [enable_shared_bucket_access](https://developer.couchbase.com/documentation/mobile/1.5/guides/sync-gateway/config-properties/index.html#1.5/databases-foo_db-enable_shared_bucket_access)
              - [import_docs](https://developer.couchbase.com/documentation/mobile/1.5/guides/sync-gateway/config-properties/index.html#1.5/databases-foo_db-import_docs)
              
              Restart the Sync Gateway node.
              
              ```bash
              [node2-sg] $ sudo systemctl restart sync_gateway
              ```
              
              The import process may take a moment. You can monitor the progress in the logs.
              
              ```bash
              [node2-sg] $ sudo tail -n 50 -f /home/sync_gateway/logs/sync_gateway_error.log
              ```
              
              You should see log messages similar to the following.
              
              ```bash
              2017-11-10T10:00:36.596Z Import+: Attempting to import doc "route_3673"...
              2017-11-10T10:00:36.597Z Import+: Attempting to import doc "route_57612"...
              2017-11-10T10:00:36.598Z Import+: Attempting to import doc "route_54528"...
              2017-11-10T10:00:36.599Z Import+: Attempting to import doc "route_36462"...
              2017-11-10T10:00:36.600Z Import+: Attempting to import doc "route_59526"...
              2017-11-10T10:00:36.600Z Import+: Attempting to import doc "route_21790"...
              2017-11-10T10:00:36.602Z Import+: Attempting to import doc "route_4576"...
              2017-11-10T10:00:36.612Z Import+: Attempting to import doc "route_57863"...
              ...
              ```
              
              Once the import process has completed you can verify that the mobile metadata previously embedded in the `_sync` property of the document body has been moved out.
              
              ![](https://cl.ly/0p3q362W262G/post-import.png)
              
              That mobile metadata now lives in the document's extended attributes. In Couchbase Server 5.0, there is currently no way to view those extended attributes through the Console UI but they are access on the Sync Gateway's `/{db}/_raw/{id}` Admin REST API endpoint.
              
              ```bash
              $ vagrant ssh node2-sg
              [node2-sg] $ curl 'localhost:4985/travel-sample/_raw/airport_5568'
              ```
              
              As expected, this time, the response contains the mobile metadata under the `_sync` property.
              
              ```bash
              {"_id":"airport_5568","_rev":"1-660749e2cc7ade88365c78845f5963ad","_sync":{"rev":"1-660749e2cc7ade88365c78845f5963ad","sequence":1087,"history":{"revs":["1-660749e2cc7ade88365c78845f5963ad"],"parents":[-1],"channels":[null]},"cas":"0x0000b5ba1eb1f514","time_saved":"0001-01-01T00:00:00Z"},"airportname":"Stronsay Airport","city":"Stronsay","country":"United Kingdom","faa":"SOY","geo":{"alt":39,"lat":59.1553,"lon":-2.64139},"icao":"EGER","id":5568,"type":"airport","tz":"Europe/London"}
              ```
              
              Query the documents **node2-sg** again at [http://10.150.150.102:4984/travel-sample/_all_docs?limit=10](http://10.150.150.102:4984/travel-sample/_all_docs?limit=10).
              
              Perform the same steps on **node5-sg**. But this time, the `import_docs` property should not be used because only 1 Sync Gateway node should be assigned the task of generating the mobile metadata for incoming documents inserted through N1QL or the Server SDKs.
              
              ```bash
              $ vagrant ssh node5-sg
              [node5-sg] $ sudo vi /home/sync_gateway/sync_gateway.json
              ```
              
              Configuration file.
              
              ```bash
              {
                "log": ["HTTP+"],
                "adminInterface": "127.0.0.1:4985",
                "interface": "0.0.0.0:4984",
                "databases": {
                  "travel-sample": {
                    "server": "http://10.150.150.101,10.150.150.103,10.150.150.104:8091",
                    "bucket": "travel-sample",
                    "user": "travel-sample",
                    "password": "password",
                    "enable_shared_bucket_access": true,
                    "users": {
                      "GUEST": {"disabled": false, "admin_channels": ["*"] }
                    }
                  }
                }
              }
              ```
              
              ```bash
              [node5-sg] $ sudo systemctl restart sync_gateway
              [node5-sg] $ sudo tail -n 50 -f /home/sync_gateway/logs/sync_gateway_error.log
              ```
              
              Query the same documents on **node5-sg** [http://10.150.150.105:4984/travel-sample/_all_docs?limit=10](http://10.150.150.105:4984/travel-sample/_all_docs?limit=10) and **node6-nginx** [http://10.150.150.106:4984/travel-sample/_all_docs?limit=10](http://10.150.150.106:4984/travel-sample/_all_docs?limit=10) to verify everything the documents can be access on the second Sync Gateway node and through NGINX.
              
              Congratulations! You have successfully performed a rolling upgrade of the 2 Sync Gateway + 3 Couchbase Server 4.6 cluster to 5.0 and can now use the N1QL, Server and Mobile SDKs on the same bucket.